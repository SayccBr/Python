import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression, LogisticRegression
import warnings
warnings.filterwarnings('ignore')

print("üìö FUNDAMENTOS TE√ìRICOS - DEMONSTRA√á√ÉO PR√ÅTICA")
print("=" * 55)

# ================================================================
# DATASET SUPER SIMPLES PARA DEMONSTRA√á√ÉO
# ================================================================

print("\nüè† CRIANDO DATASET M√çNIMO PARA DEMONSTRA√á√ÉO...")

# Apenas 12 casas para facilitar o entendimento
area_m2 = np.array([50, 70, 90, 110, 130, 150, 60, 80, 100, 120, 140, 160])
preco_mil = np.array([200, 250, 300, 350, 400, 450, 220, 270, 320, 370, 420, 470])

# DataFrame para visualiza√ß√£o
df_simples = pd.DataFrame({
    'area_m2': area_m2,
    'preco_mil': preco_mil
})

print("‚úÖ Dataset com 12 casas criado!")
print(f"\nüìä DADOS COMPLETOS:")
print(df_simples)

# ================================================================
# PARTE 1: ENTENDENDO A REGRESS√ÉO LINEAR NA PR√ÅTICA
# ================================================================

print("\n" + "="*55)
print("üìà PARTE 1: REGRESS√ÉO LINEAR - PASSO A PASSO")
print("="*55)

# Visualiza√ß√£o inicial dos dados
plt.figure(figsize=(15, 5))

plt.subplot(1, 3, 1)
plt.scatter(area_m2, preco_mil, color='blue', s=100, alpha=0.7)
plt.xlabel('√Årea (m¬≤)')
plt.ylabel('Pre√ßo (mil R$)')
plt.title('Dados Originais')
plt.grid(True, alpha=0.3)

# Ajustando o modelo linear
X = area_m2.reshape(-1, 1)  # sklearn precisa de matriz 2D
y = preco_mil

modelo_linear = LinearRegression()
modelo_linear.fit(X, y)

# Fazendo predi√ß√µes
y_pred = modelo_linear.predict(X)

# Extraindo coeficientes
intercepto = modelo_linear.intercept_
coeficiente = modelo_linear.coef_[0]

print(f"\nüîç EQUA√á√ÉO ENCONTRADA:")
print(f"   Pre√ßo = {intercepto:.2f} + {coeficiente:.2f} √ó √Årea")
print(f"   ou seja: Pre√ßo = {intercepto:.2f} + {coeficiente:.2f} √ó √Årea")

print(f"\nüí° INTERPRETA√á√ÉO:")
print(f"   ‚Ä¢ Intercepto ({intercepto:.2f}): Pre√ßo base quando √°rea = 0")
print(f"   ‚Ä¢ Coeficiente ({coeficiente:.2f}): A cada 1m¬≤ a mais, o pre√ßo sobe R$ {coeficiente:.2f}k")

# Visualizando a linha de regress√£o
plt.subplot(1, 3, 2)
plt.scatter(area_m2, preco_mil, color='blue', s=100, alpha=0.7, label='Dados Reais')
plt.plot(area_m2, y_pred, color='red', linewidth=3, label='Linha de Regress√£o')
plt.xlabel('√Årea (m¬≤)')
plt.ylabel('Pre√ßo (mil R$)')
plt.title('Regress√£o Linear Ajustada')
plt.legend()
plt.grid(True, alpha=0.3)

# Mostrando os res√≠duos (erros)
residuos = preco_mil - y_pred
plt.subplot(1, 3, 3)
plt.scatter(area_m2, residuos, color='green', s=100, alpha=0.7)
plt.axhline(y=0, color='red', linestyle='--', linewidth=2)
plt.xlabel('√Årea (m¬≤)')
plt.ylabel('Res√≠duos (Erro)')
plt.title('An√°lise de Res√≠duos')
plt.grid(True, alpha=0.3)

plt.tight_layout()
plt.show()

print(f"\nüéØ AN√ÅLISE DOS RESULTADOS:")
print(f"   ‚Ä¢ R¬≤ Score: {modelo_linear.score(X, y):.3f} (explica {modelo_linear.score(X, y)*100:.1f}% da varia√ß√£o)")
print(f"   ‚Ä¢ Erro m√©dio absoluto: {np.mean(np.abs(residuos)):.2f} mil R$")

print(f"\nüîÆ EXEMPLO DE PREDI√á√ÉO:")
nova_area = 125
preco_predito = intercepto + coeficiente * nova_area
print(f"   ‚Ä¢ Casa de {nova_area}m¬≤: Pre√ßo predito = {preco_predito:.2f} mil R$")

# Mostrando predi√ß√µes para todas as casas
print(f"\nüìã COMPARA√á√ÉO REAL vs PREDITO:")
for i in range(len(area_m2)):
    erro = abs(preco_mil[i] - y_pred[i])
    print(f"   Casa {i+1:2d}: {area_m2[i]:3d}m¬≤ ‚Üí Real: {preco_mil[i]:3d}k, Pred: {y_pred[i]:5.1f}k, Erro: {erro:4.1f}k")

# ================================================================
# PARTE 2: ENTENDENDO A REGRESS√ÉO LOG√çSTICA
# ================================================================

print("\n" + "="*55)
print("üè∑Ô∏è PARTE 2: REGRESS√ÉO LOG√çSTICA - PASSO A PASSO")
print("="*55)

# Criando classifica√ß√£o bin√°ria baseada na mediana
mediana_preco = np.median(preco_mil)
y_binario = (preco_mil > mediana_preco).astype(int)  # 1 = cara, 0 = barata

print(f"\nüéØ TRANSFORMANDO EM PROBLEMA DE CLASSIFICA√á√ÉO:")
print(f"   ‚Ä¢ Limiar (mediana): {mediana_preco:.0f} mil R$")
print(f"   ‚Ä¢ Casas 'Caras' (1): {sum(y_binario)} casas")
print(f"   ‚Ä¢ Casas 'Baratas' (0): {sum(1-y_binario)} casas")

print(f"\nüìã CLASSIFICA√á√ÉO DAS CASAS:")
for i in range(len(area_m2)):
    classe = "Cara" if y_binario[i] == 1 else "Barata"
    print(f"   Casa {i+1:2d}: {area_m2[i]:3d}m¬≤, {preco_mil[i]:3d}k ‚Üí {classe}")

# Treinando modelo log√≠stico
modelo_logistico = LogisticRegression(random_state=42)
modelo_logistico.fit(X, y_binario)

# Predi√ß√µes
y_pred_classe = modelo_logistico.predict(X)
y_pred_proba = modelo_logistico.predict_proba(X)[:, 1]  # Probabilidade de ser cara

# Coeficientes da regress√£o log√≠stica
intercepto_log = modelo_logistico.intercept_[0]
coeficiente_log = modelo_logistico.coef_[0][0]

print(f"\nüîç EQUA√á√ÉO LOG√çSTICA ENCONTRADA:")
print(f"   z = {intercepto_log:.3f} + {coeficiente_log:.5f} √ó √Årea")
print(f"   P(Casa Cara) = 1 / (1 + e^(-z))")

print(f"\nüí° INTERPRETA√á√ÉO:")
print(f"   ‚Ä¢ Coeficiente positivo ({coeficiente_log:.5f}): √Årea maior ‚Üí Maior prob. de ser cara")
print(f"   ‚Ä¢ Quanto maior a √°rea, maior a probabilidade de ser classificada como cara")

# Visualiza√ß√£o da regress√£o log√≠stica
plt.figure(figsize=(15, 5))

# Dados com classifica√ß√£o
plt.subplot(1, 3, 1)
cores = ['red' if classe == 0 else 'blue' for classe in y_binario]
plt.scatter(area_m2, y_binario, c=cores, s=100, alpha=0.7)
plt.xlabel('√Årea (m¬≤)')
plt.ylabel('Classe (0=Barata, 1=Cara)')
plt.title('Classifica√ß√£o das Casas')
plt.axhline(y=0.5, color='black', linestyle='--', alpha=0.5)
plt.grid(True, alpha=0.3)

# Fun√ß√£o sigm√≥ide
area_continua = np.linspace(40, 170, 100)
z_continuo = intercepto_log + coeficiente_log * area_continua
prob_continua = 1 / (1 + np.exp(-z_continuo))

plt.subplot(1, 3, 2)
plt.scatter(area_m2, y_pred_proba, c=cores, s=100, alpha=0.7, label='Dados')
plt.plot(area_continua, prob_continua, 'green', linewidth=3, label='Curva Sigm√≥ide')
plt.axhline(y=0.5, color='black', linestyle='--', alpha=0.5, label='Limiar 50%')
plt.xlabel('√Årea (m¬≤)')
plt.ylabel('P(Casa Cara)')
plt.title('Probabilidades Preditas')
plt.legend()
plt.grid(True, alpha=0.3)

# Compara√ß√£o das classifica√ß√µes
acertos = sum(y_binario == y_pred_classe)
acuracia = acertos / len(y_binario)

plt.subplot(1, 3, 3)
resultados = ['Correto' if real == pred else 'Erro' for real, pred in zip(y_binario, y_pred_classe)]
cores_resultado = ['green' if r == 'Correto' else 'red' for r in resultados]
plt.scatter(range(len(area_m2)), y_binario, c=cores_resultado, s=100, alpha=0.7)
plt.xlabel('√çndice da Casa')
plt.ylabel('Classe Real')
plt.title(f'Acertos vs Erros (Acur√°cia: {acuracia:.2f})')
plt.grid(True, alpha=0.3)

plt.tight_layout()
plt.show()

print(f"\nüéØ AN√ÅLISE DOS RESULTADOS LOG√çSTICOS:")
print(f"   ‚Ä¢ Acur√°cia: {acuracia:.3f} ({acuracia*100:.1f}% de acertos)")
print(f"   ‚Ä¢ Acertos: {acertos} de {len(y_binario)} casas")

print(f"\nüìã RESULTADOS DETALHADOS:")
for i in range(len(area_m2)):
    real_classe = "Cara" if y_binario[i] == 1 else "Barata"
    pred_classe = "Cara" if y_pred_classe[i] == 1 else "Barata"
    probabilidade = y_pred_proba[i]
    resultado = "‚úì" if y_binario[i] == y_pred_classe[i] else "‚úó"
    print(f"   Casa {i+1:2d}: {area_m2[i]:3d}m¬≤ ‚Üí Real: {real_classe:6s}, Pred: {pred_classe:6s}, Prob: {probabilidade:.3f} {resultado}")

print(f"\nüîÆ EXEMPLO DE NOVA PREDI√á√ÉO:")
nova_area_log = 125
z_novo = intercepto_log + coeficiente_log * nova_area_log
prob_novo = 1 / (1 + np.exp(-z_novo))
classe_nova = "Cara" if prob_novo > 0.5 else "Barata"
print(f"   ‚Ä¢ Casa de {nova_area_log}m¬≤: P(Cara) = {prob_novo:.3f}, Classifica√ß√£o: {classe_nova}")

# ================================================================
# COMPARA√á√ÉO ENTRE OS DOIS M√âTODOS
# ================================================================

print("\n" + "="*55)
print("üîÑ COMPARA√á√ÉO ENTRE REGRESS√ÉO LINEAR E LOG√çSTICA")
print("="*55)

fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))

# Regress√£o Linear
ax1.scatter(area_m2, preco_mil, color='blue', s=100, alpha=0.7, label='Dados Reais')
ax1.plot(area_m2, y_pred, color='red', linewidth=3, label='Regress√£o Linear')
ax1.set_xlabel('√Årea (m¬≤)')
ax1.set_ylabel('Pre√ßo (mil R$)')
ax1.set_title('Regress√£o Linear\n(Predi√ß√£o Cont√≠nua)')
ax1.legend()
ax1.grid(True, alpha=0.3)

# Regress√£o Log√≠stica
cores = ['red' if classe == 0 else 'blue' for classe in y_binario]
ax2.scatter(area_m2, y_binario, c=cores, s=100, alpha=0.7, label='Classes Reais')
ax2.plot(area_continua, prob_continua, 'green', linewidth=3, label='Regress√£o Log√≠stica')
ax2.axhline(y=0.5, color='black', linestyle='--', alpha=0.5, label='Limiar 50%')
ax2.set_xlabel('√Årea (m¬≤)')
ax2.set_ylabel('P(Casa Cara)')
ax2.set_title('Regress√£o Log√≠stica\n(Classifica√ß√£o)')
ax2.legend()
ax2.grid(True, alpha=0.3)

plt.tight_layout()
plt.show()

print(f"\nüéØ PRINCIPAIS DIFEREN√áAS:")
print(f"   ‚Ä¢ LINEAR: Prediz valores cont√≠nuos (pre√ßo exato)")
print(f"   ‚Ä¢ LOG√çSTICA: Prediz probabilidades e classes (cara/barata)")
print(f"   ‚Ä¢ LINEAR: Pode dar qualquer valor")
print(f"   ‚Ä¢ LOG√çSTICA: Sempre entre 0 e 1 (probabilidades)")

print(f"\nüí° QUANDO USAR CADA UM:")
print(f"   ‚Ä¢ REGRESS√ÉO LINEAR:")
print(f"     ‚úì Quando voc√™ quer prever um valor num√©rico")
print(f"     ‚úì Ex: pre√ßo, temperatura, vendas, peso")
print(f"   ‚Ä¢ REGRESS√ÉO LOG√çSTICA:")
print(f"     ‚úì Quando voc√™ quer classificar em categorias")
print(f"     ‚úì Ex: spam/n√£o-spam, aprovado/reprovado, doente/saud√°vel")

# ================================================================
# CONCEITOS MATEM√ÅTICOS IMPORTANTES
# ================================================================

print(f"\n" + "="*55)
print("üßÆ CONCEITOS MATEM√ÅTICOS FUNDAMENTAIS")
print("="*55)

print(f"\nüìê M√âTODO DOS M√çNIMOS QUADRADOS (Regress√£o Linear):")
print(f"   ‚Ä¢ Objetivo: Minimizar Œ£(yi - ≈∑i)¬≤")
print(f"   ‚Ä¢ Em portugu√™s: Minimizar a soma dos quadrados dos erros")
print(f"   ‚Ä¢ No nosso exemplo: Œ£ dos erros¬≤ = {sum(residuos**2):.2f}")

print(f"\nüìä FUN√á√ÉO SIGM√ìIDE (Regress√£o Log√≠stica):")
print(f"   ‚Ä¢ F√≥rmula: œÉ(z) = 1 / (1 + e^(-z))")
print(f"   ‚Ä¢ Mapeia qualquer valor real para [0,1]")
print(f"   ‚Ä¢ Forma de 'S': cresce suavemente de 0 para 1")

print(f"\nüéØ M√âTRICAS DE AVALIA√á√ÉO:")
print(f"   ‚Ä¢ REGRESS√ÉO LINEAR:")
print(f"     - R¬≤: {modelo_linear.score(X, y):.3f} (% da varia√ß√£o explicada)")
print(f"     - MSE: {np.mean(residuos**2):.2f} (erro quadr√°tico m√©dio)")
print(f"     - RMSE: {np.sqrt(np.mean(residuos**2)):.2f} (erro na unidade original)")
print(f"   ‚Ä¢ REGRESS√ÉO LOG√çSTICA:")
print(f"     - Acur√°cia: {acuracia:.3f} (% de acertos)")
print(f"     - Log-likelihood: Mede a 'probabilidade' dos dados dado o modelo")

print(f"\n‚úÖ CONCEITOS FUNDAMENTAIS DEMONSTRADOS COM SUCESSO!")
print(f"   Com apenas 12 casas, conseguimos entender:")
print(f"   ‚Ä¢ Como funciona a regress√£o linear")
print(f"   ‚Ä¢ Como funciona a regress√£o log√≠stica") 
print(f"   ‚Ä¢ As diferen√ßas pr√°ticas entre elas")
print(f"   ‚Ä¢ Como interpretar os resultados")